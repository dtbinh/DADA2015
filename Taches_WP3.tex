\subsubsection{WP3 Authoring}


\begin{center}
\begin{tabular}{|l|l|}\hline
WP3 &  Authoring \\\hline
Responsable &  Inria  \\\hline
Participants &  Paris 8, ECM, Telecom ParisTech\\\hline
Duration  &   \\\hline
Objectives &   \\\hline
Content &  \\\hline
Task 31 & Blocking language  \\\hline
Task12 &  Authoring tools \\\hline
Task13 &  Real-time animation  \\\hline
\end{tabular}
\end{center}


\paragraph{Task31: Specification of a dramatic language for virtual actors.}

Previous work in autonomous agents has focused on defining non-verbal communication languages at the functional level (what is being communicated) and the behavioral level (how it is communicated using body language). While a consensus has slowly been reached on the behavioral level with the BML language (REFS), a genera framework for describing non- verbal communicationat the functional level remains elusive (REF). In DADA, we will take a very different route by giving specifications only for dramaturgic actions,
i.e. actions whose purpose is to be played on a stage and communicated to an audience.

This will include a choice of verbs (actions, speech acts, movements) and adverbs (moods, attitudes, dramatic effects) 
for directing actors ; and a choice of cues acting as synchronisation points between actors.

The research problems to be solved in this task include the definition of parallel and sequential behaviors
for single, isolated actors; the definition of parallel and sequential behaviors for groups of actors; an intuitive and general 
syntax for control the synchronisation between them; the choice of non redundant action primitives; and the choice of meaning parameters to be exposed to the director (as opposed to resolved internally by the animation engine).

In agreement with the organization of tasks in WP1 and WP2, the specification will clearly separate proxemic
and kinesic elements of actors' behaviors. Furthermore, our goal will be to cover both the movements of actors
on the stage, and their communicative behaviors during dialogue. 

As a result of this task, we will be proposing an extended blocking notation for theatre performances, akin to a musical score\cite{gagnere2012,ronfard2012,gagnere2015}. Part of this language will be devoted to stage blocking / movement.
Part of this language will be devoted to dialogue. The proposed specification will be given in the form of a pseudo-natural language
that makes sense to the director, and can at the same time be compiled into a machine representation. Internally, the representation
will likely be based on Petri nets, which provides an intuitive and general representation of multi-modal, parallel processes with complex
synchronization cues ; and at the same time can easily be resolved into hierarchical finite state machines, which can be executed efficiently in a game engine.

The specification  will borrow important terms from the language of theatre:  blockings, cues and prompts,  which we explain briefly now. In theatre, blocking is the precise movement and staging of actors on a stage in order to facilitate the performance of a play, ballet, film or opera. A theatrical cue is the trigger for an action to be carried out at a specific time. It is generally associated with theatre and the film industry. They can be necessary for a lighting change or effect, a sound effect, or some sort of stage or set movement/change. A cue sheet is a form usually generated by the stage manager or design department head that indicates information about the cue including execution, timing, sequence, intensity (for lights), and volume (for sound). The stage manager keeps a master list of all the cues in the show and keeps track of them in the prompt book. The Prompt Book is the master copy of the script or score, containing all the actor moves and technical cues,  and is used by the deputy stage manager to run rehearsals and later, control the performance.

The specification will be delivered in two increments. The first increment will focus on directing individual actors and synchronizing
their actions. The second increment will focus on directing groups of actors and synchronizing the actions of actors within the group, and even between groups.

\paragraph{Task32: Authoring tools.}

For the DADA platform to be accepted by theatre directors, it is important that we offer authoring tools that make sense to them. 
Although we are focusing Petri nets or related frameworks as an internal representation, our goal in task 32 will be to hide this internal representation as much as possible, and instead to offer three modes of interaction: didascalia, storyboard sketches, and timelines.

Even if the internal representation of Design and implementation of authoring tools for creating animation with the dramatic language.
with natural interaction, taking inspiration from existing practices in theatre (prompt-books, cue sheet, storyboards, etc.).

\paragraph{Didascalia} bla bla bla

\paragraph{Storyboard sketches} bla bla bla

\paragraph{Timelines} bla bla bla

The authoring tool may include multimodal interaction with the director: sketching tools for designing actor trajectories
and meeting points; writing tools for adding didascalia to dialogues; timeline-driven interaction for defining cue points
and actions, timing, etc. User interface for directing actors by sketching stage floor plans and composing the dramatic score ; one line per actor per motion component (proxemic behaviors, kinesic actions, kinesic moods, speech acts, etc.) Compilation of the language into a finite state machine and/or Petri net ; allowing real-time execution of the dramatic score.


\paragraph{Task33: Real-time execution of the dramatic score.} 

While task 31 focuses on defining the vocabulary and syntax of the dramatic score, and task 32 focuses on implementing 
a score-writing application, the role of task 33 will be to implement a realizer/synthesizer for executing the dramatic score.

This should include real-time combination of proxemic (procedural) and kinesic components of motion ; non-deterministic motion generation ; synchronization to cues ; real-time skinning and advanced 3D animation ; integration of physically-based secondary animation (skin, hair, clothes, etc.).  This includes integration of the GRETA BML realizer with IMAGINE animation ; and real-time integration of the statistical models of motion with the procedural animation components.


One challenge to be overcome is in combining full 	body animation and interaction animation at runtime. We believe it will be an importa asset for the DADA platform that each performance is unique, and can be controled in real time by cues given by the director. 
  We will pay particular attention to design models capable of generating real animations. Indeed synthezing from statistical models usually resumes to finding the most likely animation sequence in a given situation, which may yield to too similar and unrealistic animations.  Actually one would be pretty much interested in synthezing animations that are both likely given the learnt statistical models but also exhibiting the variability one can observe in human motion and gestures. Introducing such a stochastic component in the synthesis while maintaining a high quality animation level is not  straightforward and is an open question that we will have to solve.

Combining proxemics and kinesics components can be done along the lines of Mitake et al. \cite{Mitake09}, where
the degrees of freedom of a virtual character are separated into six parameters for rigid body simulations,  and four parameters
for encoding multi-dimensional keyframe animations. Similarly, we would like to hide the complexity of high-dimensional 
character animation (with 40-60 degrees of freedom) behind a small number of control parameters. We will extend
rigid body simulations  to include proxemic interaction forces in WP2. And we will replace keyframe animations with statistical models learned from data in WP1. 

One promising avenue for research will be to design strategies for controlling the proxemic components of character animation
using the rigid motion of the head, rather than the full body.  Sreenivasa et al. \cite{Sreenivasa09} have proposed inverse kinematics methods for computing  the body motion of a humanoid robot, including footsteps and walking patterns of motion, given its head motion. In the context of DADA, the head motion of the virtual actors could similarly be put under the direct control of the director because it plays such an important expressive and dramatic function. The full body motion could then be computed with the constraints that the actor's head motion matches the director's directions, and the prescribed actions (walking, sitting, standing, etc.) and attitudes (sadly, swiftly, merrily, etc.).


\paragraph{Partners' roles}

Inria will be the main software developper.

Task 3.1 will be jointly performed by Inria, LITC and Paris 8.

LIF will contribute to task 3.3 on implementing non-deterministic animation 
methods using statistical models trained in WP1.

Paris 8 will contribute to tasks 3.2 and 3.3 by being the "product owner" for the authoring tool.

LITC will contribute to task   3.3 by providing a subset of the GRETA platform.





\paragraph{Deliverables}

bla bla

\begin{tabular}{|l|l|l|}\hline
Deliverables & Name and content  & Date  \\\hline
L1.1  & Report on the state of the art for virtual theatre & \\\hline
L1.2  &  & \\\hline
L1.3  &  & \\\hline
\end{tabular}


\endinput
