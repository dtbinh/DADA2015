\subsubsection{WP3 Authoring}


\begin{center}
\begin{tabular}{|l|l|}\hline
WP3 &  Authoring \\\hline
Responsable &  Inria  \\\hline
Participants &  Paris 8, LIF, LTCI\\\hline
Duration  &   36 months \\\hline
Objectives &  Authoring and execution of virtual actor performances  \\\hline
Content &  \\\hline
Task 31 & Specification of the dramatic score language  ($T_0 \rightarrow  T_0+12$)  \\\hline
Task12 &  Authoring tools  ($T_0+12 \rightarrow  T_0+36$)  \\\hline
Task13 &  Real-time animation   ($T_0+12 \rightarrow  T_0+36$)  \\\hline
\end{tabular}
\end{center}


\paragraph{Task 3.1 : Specification of a dramatic score language}

Previous work in autonomous agents has focused on defining non-verbal communication languages at the functional level (what is being communicated) and the behavioral level (how it is communicated using body language). While a consensus has slowly been reached on the behavioral level with the BML language \cite{Kopp2006}, a general framework for describing non-verbal communication at the functional level remains elusive. In DADA, we will take a very different route by giving specifications only for dramaturgic actions, i.e. actions whose purpose is to be played on a stage and communicated to an audience. This will include a choice of verbs (actions, speech acts, movements) and adverbs (moods, attitudes, dramatic effects)  for directing actors ; and a choice of cues acting as synchronization points between actors.

The research problems to be solved in this task include the definition of parallel and sequential behaviors for single, isolated actors; the definition of parallel and sequential behaviors for groups of actors; an intuitive and general  syntax for control the synchronization between them; the choice of non redundant action primitives; and the choice of meaning parameters to be exposed to the director (as opposed to resolved internally by the animation engine). In agreement with the organization of tasks in WP1 and WP2, the specification will clearly separate proxemic and kinesic elements of actor behaviors. Furthermore,  our goal will be to cover both the movements of actors on the stage, and their communicative behaviors during dialogue. 

As a result of this task, we will be proposing an extended notation for theatre performances, akin to a musical score \cite{gagnere2012,ronfard2012,gagnere2015}. For lack of another word, we
will refer to this future notation scheme as  the {\em  dramatic score}. To define the syntax and semantic of the dramatic score, we will draw  on  previous work on the dramaturgical score \cite{Elam2002}, which takes a semiotics approach, and on established stage management practices in the theatre \cite{Maccoy2004}. The proposed specification will be given in the form of a pseudo-natural language that makes sense to the director, and can at the same time be compiled into a machine representation. Internally, the representation will likely be based on Petri nets, which provides an intuitive and general representation of multi-modal, parallel processes with complex synchronization cues ; and at the same time can easily be resolved into hierarchical finite state machines, which can be executed efficiently in a game engine.

The specification  will borrow important terms from the language of theatre \cite{Maccoy2004}:  blockings, cues and prompts,  which we explain briefly now. In theatre, blocking is the precise movement and staging of actors on a stage in order to facilitate the performance of a play, ballet, film or opera. A theatrical cue is the trigger for an action to be carried out at a specific time. A cue sheet is a form usually generated by the stage manager or design department head that indicates information about the cue including execution, timing, sequence, intensity (for lights), and volume (for sound). The stage manager keeps a master list of all the cues in the show and keeps track of them in the prompt book. The Prompt Book is the master copy of the script or score, containing all the actor moves and technical cues,  and is used by the   stage manager to run rehearsals and later, control the performance. Such traditional notions will need to be thoroughly extended to take into account the 
entirely novel situation of computer-controlled virtual actors.

The specification will be delivered in two increments. The first increment will focus on directing individual actors and synchronizing their actions. The second increment will focus on directing groups of actors and synchronizing their actions  within the group, and  across different  groups.

\paragraph{Task3.2 : Authoring tools}

For the DADA platform to be accepted by theatre directors, it is important that we offer authoring tools that make sense to them. 
Although we are targeting  Petri nets as an internal representation, our goal in task 32 will be to hide this internal representation 
from users. Instead, we we will offer three modes of interaction: didascalia, storyboard sketches, and timelines. Didascalia will
be offered as blocks of text with a controled vocabulary and a choice of parameters allowing the director to define cues, actions and their parameters 
in plain text.  Storyboard sketches will be used to represent the actors positions, orientations and trajectories using a combination of floor-plan views 
and audience views. Timelines will be used to set the starting and ending points of performing events by direct manipulation. There will likely be
one timeline per actor per animation component (proxemic behaviors, kinesic actions, kinesic moods, speech acts, etc.).

As a result, the authoring tools will include multimodal interaction with the director: sketching tools for designing actor trajectories and meeting points; 
writing tools for adding didascalia to dialogues; timeline-driven interaction for defining cue points, actions and timing. 

%User interface  for directing actors by sketching stage floor plans and composing the performing score ; 

% Compilation of the language into a finite state machine and/or Petri net ; allowing real-time execution of the dramatic score.


\paragraph{Task 3.3 : Real-time execution of the dramatic score} 

While task 31 focuses on defining the vocabulary and syntax of the dramatic score, and task 32 focuses on implementing 
a score-writing application, the role of task 33 will be to implement a realizer/synthesizer for executing the dramatic score.
This should include real-time combination of proxemic (procedural) and kinesic components of motion ; non-deterministic motion generation ; synchronization to cues ; real-time skinning and advanced 3D animation ; integration of physically-based secondary animation (skin, hair, clothes, etc.).  This includes integration of the GRETA BML realizer with IMAGINE animation ; and real-time integration of the statistical models of motion with the procedural animation components.

Another challenge to be overcome is in combining full body animation and interaction animation at runtime. We believe it will be an important asset for the DADA platform that each performance is unique, and can be controled in real time by cues given by the director.  We will pay particular attention to design models capable of generating real animations. Indeed synthezing from statistical models usually resumes to finding the most likely animation sequence in a given situation, which may yield to too similar and unrealistic animations.  Actually one would be pretty much interested in synthezing animations that are both likely given the learnt statistical models but also exhibiting the variability one can observe in human motion and gestures. Introducing such a stochastic component in the synthesis while maintaining a high quality animation level is not  straightforward and is an open question that we will have to solve.

Special care will be needed for combining the proxemic and kinesic components of animation at runtime along the lines of Mitake et al. \cite{Mitake09}, 
where the degrees of freedom of a virtual character are separated into six parameters for rigid body simulations,  and four parameters for encoding multi-dimensional keyframe animations. Similarly, we would like to hide the complexity of high-dimensional  character animation (with 40-60 degrees of freedom) behind a small number of control parameters. We will extend rigid body simulations  to include proxemic interaction forces in WP2. And we will replace keyframe animations with statistical models learned from data in WP1. 

Another research issue that will be investigated in this task  is the possibility  of  controlling the proxemic components of character animation using the rigid motion of the head, rather than the full body.  Sreenivasa et al. \cite{Sreenivasa09} have proposed inverse kinematics methods for computing  the body motion of a humanoid robot, including footsteps and walking patterns of motion, given its head motion. In the context of DADA, the head motion of the virtual actors could similarly be put under the direct control of the director because it plays such an important expressive and dramatic function. The full body motion could then be computed with the constraints that the actor's head motion matches the director's directions, and the prescribed actions (walking, sitting, standing, etc.) and attitudes (sadly, swiftly, merrily, etc.).


\vspace{1cm}

\begin{tabular}{|l|p{10cm}|l|}\hline
Deliverables & Name and content  & Date  \\\hline
L3.1  & Specification of the dramatic score language &  $T_0+12$   \\\hline
L3.2  & First version of authoring tools and execution environment : Prototype (software) and its documentation &  $T_0+24$  \\\hline
L3.3  & Second version of authoring tools and execution environment : Prototype (software) and its documentation &  $T_0+36$   \\\hline
\end{tabular}

\paragraph{Partners' roles}
Inria will be the coordinator and main software developer for this work package.  Task 3.1 will be jointly performed by Inria, LTCI and Paris 8.
LIF will contribute to task 3.3 on implementing non-deterministic animation  methods using statistical models trained in WP1. Paris 8 will contribute 
to tasks 3.2 and 3.3 by being the "product owner" for the authoring tool and runtime environment. LTCI will contribute to task   3.3 by providing a subset 
of the GRETA platform.

\paragraph{Risks}
This ambition in this task is potentially very high. We will devote special attention to  ensure that the first prototype on single-actor animation 
uses established and existing  technologies from all partners, and can be shared by all partners at an early stage in the project. This will make
it easier to maintain control of the potential more risky second prototype. The role of Paris 8 as a product owner will be crucial in helping the 
consortium maintain a functional and tested code base over the duration of the project. As a result, the risks will be limited.

\endinput
