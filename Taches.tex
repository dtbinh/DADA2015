
\subsection{Description des travaux par tâche / Description by task}
\begin{xcomment}  
Pour chaque tâche, d\'ecrire : 
les objectifs et \'eventuels indicateurs de succ\`es,
les personnes impliqu\'ees,
le programme d\'etaill\'e des travaux,
les livrables,
les contributions des personnes (le qui fait quoi ),
la description des m\'ethodes et des choix techniques et de la mani\`ere dont les solutions seront apport\'ees,
les risques et les solutions de repli envisag\'ees.
\end{xcomment}




\input{Taches_WP1}
\input{Taches_WP2}
\input{Taches_WP3}
\input{Taches_WP4}


Additional notes


We will dedicate joint research between Inria and LIF to make it easy to extend our database of actions and attitudes
using video, rather than motion capture. This will necessitate fundamental research in transfer learning (so that the sparse
data obtained from video can benefit from the dense data obtained with motion capture) and video processing.  Following the
methodology of  gesture controllers \cite{Levine2010}, where the gesture are controlled directly by speech prosody features
extracted from real actors voices, it appears possible to drive expressive and plausible gestures and body movements from
visual signatures of actions and attitudes extracted from example videos. 

We will use  our previous work in actor and action recognition \cite{Weinland06,Weinland07,Gandhi13} to detect and recognize
actors and their actions in real movies ; and extract visual signatures of the corresponding actions and attitudes. Based on this
analysis, we will learn joint statistical models for driving gesture controllers from those video signals.


Combining proxemics and kinesics components can be done along the lines of Mitake et al. \cite{Mitake09}, where
the degrees of freedom of a virtual character are separated into six parameters for rigid body simulations,  and four parameters
for encoding multi-dimensional keyframe animations. Similarly, we would like to hide the complexity of high-dimensional 
character animation (with 40-60 degrees of freedom) behind a small number of control parameters. We will extend
rigid body simulations  to include proxemic interaction forces in WP2. And we will replace keyframe animations with statistical models learned from data in WP1. 

One promising avenue for research will be to design strategies for controlling the proxemic components of character animation
using the rigid motion of the head, rather than the full body.  Sreenivasa et al. \cite{Sreenivasa09} have proposed inverse kinematics methods for computing  the body motion of a humanoid robot, including footsteps and walking patterns of motion, given its head motion. In the context of DADA, the head motion of the virtual actors could similarly be put under the direct control of the director because it plays such an important expressive and dramatic function. The full body motion could then be computed with the constraints that the actor's head motion matches the director's directions, and the prescribed actions (walking, sitting, standing, etc.) and attitudes (sadly, swiftly, merrily, etc.).





\subsection{Calendrier des tâches, livrables et jalons / Tasks schedule, deliverables and milestones}
\begin{xcomment} 
Pr\'esenter sous forme graphique un \'ech\'eancier des diff\'erentes tâches et leurs d\'ependances (diagramme de Gantt par exemple).
Pr\'esenter un tableau synth\'etique de l'ensemble des livrables du projet (num\'ero de tâche, date, intitul\'e, responsable).
Pr\'eciser de façon synth\'etique les jalons scientifiques et/ou techniques, les principaux points de rendez-vous, les points bloquants ou al\'eas qui risquent de remettre en cause l'aboutissement du projet ainsi que les r\'eunions de projet pr\'evues.

\end{xcomment}

\endinput